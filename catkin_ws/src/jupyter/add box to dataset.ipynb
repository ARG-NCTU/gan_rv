{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "from skimage import exposure\n",
    "from skimage.transform import match_histograms\n",
    "from models import *\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_root = \"/media/arg_ws3/5E703E3A703E18EB/data/mm_unity_new/unity_boxes\"\n",
    "unity_box_img_root = \"/media/arg_ws3/5E703E3A703E18EB/data/mm_FCN/unity/box_img\"\n",
    "unity_box_mask_root = \"/media/arg_ws3/5E703E3A703E18EB/data/mm_FCN/unity/box_mask\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_list = os.listdir(box_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box_108\n",
      "box_116\n",
      "box_72\n"
     ]
    }
   ],
   "source": [
    "for box in box_list:\n",
    "    print(box)\n",
    "    scene_path = os.path.join(box_root, box)\n",
    "    scene_list = os.listdir(scene_path)\n",
    "    \n",
    "    unity_box_mask_scene_path = os.path.join(unity_box_mask_root, box)\n",
    "    if not os.path.exists(unity_box_mask_scene_path):\n",
    "        os.makedirs(unity_box_mask_scene_path)\n",
    "        \n",
    "    unity_box_img_scene_path = os.path.join(unity_box_img_root, box)\n",
    "    if not os.path.exists(unity_box_img_scene_path):\n",
    "        os.makedirs(unity_box_img_scene_path)\n",
    "        \n",
    "    for scene in scene_list:\n",
    "        data_path = os.path.join(scene_path, scene)\n",
    "        data_list = os.listdir(data_path)\n",
    "        \n",
    "        unity_box_mask_data_path = os.path.join(unity_box_mask_scene_path, scene)\n",
    "        if not os.path.exists(unity_box_mask_data_path):\n",
    "            os.makedirs(unity_box_mask_data_path)\n",
    "        \n",
    "        unity_box_img_data_path = os.path.join(unity_box_img_scene_path, scene)\n",
    "        if not os.path.exists(unity_box_img_data_path):\n",
    "            os.makedirs(unity_box_img_data_path)\n",
    "        \n",
    "        for data in data_list:\n",
    "            if \"_label\" in data:\n",
    "                mask_name = data\n",
    "                img_name = data.split(\"_label\")[0] + \"_original.png\"\n",
    "                mask_path = os.path.join(data_path, mask_name)\n",
    "                img_path = os.path.join(data_path, img_name)\n",
    "                unity_box_mask_path = os.path.join(unity_box_mask_data_path, mask_name)\n",
    "                unity_box_img_path = os.path.join(unity_box_img_data_path, img_name)\n",
    "                copyfile(mask_path, unity_box_mask_path)\n",
    "                copyfile(img_path, unity_box_img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "G_AB = GeneratorResNet(res_blocks=9)\n",
    "if cuda:\n",
    "    G_AB = G_AB.cuda()\n",
    "G_AB.load_state_dict(torch.load('/media/arg_ws3/5E703E3A703E18EB/research/cycle_box_sim2real/saved_models/box_sim2real_new/G_AB_579700_.pth'))\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "                [ transforms.Resize(int(480), Image.BICUBIC),\n",
    "                #transforms.RandomCrop((opt.img_height, opt.img_width)),\n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(tensor, nrow=8, padding=2,\n",
    "              normalize=False, range=None, scale_each=False, pad_value=0):\n",
    "    \"\"\"Make a grid of images.\n",
    "\n",
    "    Args:\n",
    "        tensor (Tensor or list): 4D mini-batch Tensor of shape (B x C x H x W)\n",
    "            or a list of images all of the same size.\n",
    "        nrow (int, optional): Number of images displayed in each row of the grid.\n",
    "            The Final grid size is (B / nrow, nrow). Default is 8.\n",
    "        padding (int, optional): amount of padding. Default is 2.\n",
    "        normalize (bool, optional): If True, shift the image to the range (0, 1),\n",
    "            by subtracting the minimum and dividing by the maximum pixel value.\n",
    "        range (tuple, optional): tuple (min, max) where min and max are numbers,\n",
    "            then these numbers are used to normalize the image. By default, min and max\n",
    "            are computed from the tensor.\n",
    "        scale_each (bool, optional): If True, scale each image in the batch of\n",
    "            images separately rather than the (min, max) over all images.\n",
    "        pad_value (float, optional): Value for the padded pixels.\n",
    "\n",
    "    Example:\n",
    "        See this notebook `here <https://gist.github.com/anonymous/bf16430f7750c023141c562f3e9f2a91>`_\n",
    "\n",
    "    \"\"\"\n",
    "    if not (torch.is_tensor(tensor) or\n",
    "            (isinstance(tensor, list) and all(torch.is_tensor(t) for t in tensor))):\n",
    "        raise TypeError('tensor or list of tensors expected, got {}'.format(type(tensor)))\n",
    "\n",
    "    # if list of tensors, convert to a 4D mini-batch Tensor\n",
    "    if isinstance(tensor, list):\n",
    "        tensor = torch.stack(tensor, dim=0)\n",
    "\n",
    "    if tensor.dim() == 2:  # single image H x W\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "    if tensor.dim() == 3:  # single image\n",
    "        if tensor.size(0) == 1:  # if single-channel, convert to 3-channel\n",
    "            tensor = torch.cat((tensor, tensor, tensor), 0)\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "\n",
    "    if tensor.dim() == 4 and tensor.size(1) == 1:  # single-channel images\n",
    "        tensor = torch.cat((tensor, tensor, tensor), 1)\n",
    "\n",
    "    if normalize is True:\n",
    "        tensor = tensor.clone()  # avoid modifying tensor in-place\n",
    "        if range is not None:\n",
    "            assert isinstance(range, tuple), \\\n",
    "                \"range has to be a tuple (min, max) if specified. min and max are numbers\"\n",
    "\n",
    "        def norm_ip(img, min, max):\n",
    "            img.clamp_(min=min, max=max)\n",
    "            img.add_(-min).div_(max - min + 1e-5)\n",
    "\n",
    "        def norm_range(t, range):\n",
    "            if range is not None:\n",
    "                norm_ip(t, range[0], range[1])\n",
    "            else:\n",
    "                norm_ip(t, float(t.min()), float(t.max()))\n",
    "\n",
    "        if scale_each is True:\n",
    "            for t in tensor:  # loop over mini-batch dimension\n",
    "                norm_range(t, range)\n",
    "        else:\n",
    "            norm_range(tensor, range)\n",
    "\n",
    "    if tensor.size(0) == 1:\n",
    "        return tensor.squeeze()\n",
    "\n",
    "    # make the mini-batch of images into a grid\n",
    "    nmaps = tensor.size(0)\n",
    "    xmaps = min(nrow, nmaps)\n",
    "    ymaps = int(math.ceil(float(nmaps) / xmaps))\n",
    "    height, width = int(tensor.size(2) + padding), int(tensor.size(3) + padding)\n",
    "    grid = tensor.new_full((3, height * ymaps + padding, width * xmaps + padding), pad_value)\n",
    "    k = 0\n",
    "    for y in irange(ymaps):\n",
    "        for x in irange(xmaps):\n",
    "            if k >= nmaps:\n",
    "                break\n",
    "            grid.narrow(1, y * height + padding, height - padding)\\\n",
    "                .narrow(2, x * width + padding, width - padding)\\\n",
    "                .copy_(tensor[k])\n",
    "            k = k + 1\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(image):\n",
    "    \"\"\"Saves a generated sample from the test set\"\"\"\n",
    "    #imgs = next(iter(val_dataloader))\n",
    "    #image = cv2.imread(\"/media/arg_ws3/5E703E3A703E18EB/data/mm_unity/unity_boxes/box_108/Scene65/11_original.png\")\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pil_im = Image.fromarray(image)\n",
    "    pil_im = data_transform(pil_im)\n",
    "    pil_im = pil_im.unsqueeze(0)\n",
    "\n",
    "    image = cv2.resize(image, (256, 256)) \n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = torch.tensor(image)\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    #print(image.shape)\n",
    "    #print(pil_im.shape)\n",
    "\n",
    "    my_img = Variable(pil_im.type(Tensor))\n",
    "    my_img_fake = G_AB(my_img)\n",
    "    my_img_fake = my_img_fake.squeeze(0).detach().cpu()\n",
    "    \n",
    "    grid = make_grid(my_img_fake, nrow=5, normalize=True)\n",
    "    pil_ = grid.mul_(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to('cpu', torch.uint8).numpy()\n",
    "    #print(pil_)\n",
    "    pil_ = np.array(pil_)\n",
    "    pil_ = pil_[...,::-1]\n",
    "    pil_ = cv2.resize(pil_, (640, 480))\n",
    "    return pil_\n",
    "    #print(pil_.dtype)\n",
    "    #cv2.imwrite(\"crop_mask1.jpg\", pil_)\n",
    "\n",
    "    #save_image(my_img_fake, 'boxxx.png', nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for box in box_list:\n",
    "    mask_name = box.split('_original.png')[0] + '_seg.png'\n",
    "    box_img = cv2.imread(os.path.join(box_root, box))\n",
    "    matched = sample_images(box_img)\n",
    "    image = cv2.imread(os.path.join(image_root, box))\n",
    "    mask_img = cv2.imread(os.path.join(mask_root, mask_name), 0)\n",
    "    mask_img[mask_img > 0] = 255\n",
    "    mask = cv2.cvtColor(mask_img, cv2.COLOR_GRAY2RGB)\n",
    "    matched = cv2.bitwise_and(matched, mask, mask=mask_img)\n",
    "    mask_img[mask_img < 255] = 1\n",
    "    mask_img[mask_img == 255] = 0\n",
    "    mask_img[mask_img == 1] = 255\n",
    "    mask = cv2.cvtColor(mask_img, cv2.COLOR_GRAY2RGB)\n",
    "    image = cv2.bitwise_and(image, mask, mask=mask_img)\n",
    "    result = cv2.add(matched, image)\n",
    "    cv2.imwrite(os.path.join(root, box), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_root = \"/media/arg_ws3/5E703E3A703E18EB/data/mm_unity_new/unity_boxes\"\n",
    "box_gan_box_img_root = \"/media/arg_ws3/5E703E3A703E18EB/data/mm_FCN/box_gan/box_img\"\n",
    "box_gan_box_mask_root = \"/media/arg_ws3/5E703E3A703E18EB/data/mm_FCN/box_gan/box_mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_list = os.listdir(box_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box_108\n",
      "box_116\n",
      "box_72\n"
     ]
    }
   ],
   "source": [
    "for box in box_list:\n",
    "    print(box)\n",
    "    scene_path = os.path.join(box_root, box)\n",
    "    scene_list = os.listdir(scene_path)\n",
    "    \n",
    "    box_gan_box_mask_scene_path = os.path.join(box_gan_box_mask_root, box)\n",
    "    if not os.path.exists(box_gan_box_mask_scene_path):\n",
    "        os.makedirs(box_gan_box_mask_scene_path)\n",
    "        \n",
    "    box_gan_box_img_scene_path = os.path.join(box_gan_box_img_root, box)\n",
    "    if not os.path.exists(box_gan_box_img_scene_path):\n",
    "        os.makedirs(box_gan_box_img_scene_path)\n",
    "        \n",
    "    for scene in scene_list:\n",
    "        data_path = os.path.join(scene_path, scene)\n",
    "        data_list = os.listdir(data_path)\n",
    "        \n",
    "        box_gan_box_mask_data_path = os.path.join(box_gan_box_mask_scene_path, scene)\n",
    "        if not os.path.exists(box_gan_box_mask_data_path):\n",
    "            os.makedirs(box_gan_box_mask_data_path)\n",
    "        \n",
    "        box_gan_box_img_data_path = os.path.join(box_gan_box_img_scene_path, scene)\n",
    "        if not os.path.exists(box_gan_box_img_data_path):\n",
    "            os.makedirs(box_gan_box_img_data_path)\n",
    "        \n",
    "        for data in data_list:\n",
    "            if \"_label\" in data:\n",
    "                mask_name = data\n",
    "                img_name = data.split(\"_label\")[0] + \"_original.png\"\n",
    "                mask_path = os.path.join(data_path, mask_name)\n",
    "                img_path = os.path.join(data_path, img_name)\n",
    "                box_gan_box_mask_path = os.path.join(box_gan_box_mask_data_path, mask_name)\n",
    "                box_gan_box_img_path = os.path.join(box_gan_box_img_data_path, img_name)\n",
    "                \n",
    "                box_img = cv2.imread(img_path)\n",
    "                matched = sample_images(box_img)\n",
    "                \n",
    "                cv2.imwrite(box_gan_box_img_path, matched)                \n",
    "                copyfile(mask_path, box_gan_box_mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CVS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68608\n"
     ]
    }
   ],
   "source": [
    "fcn_root = \"/media/arg_ws3/5E703E3A703E18EB/data/mm_FCN/unity/\"\n",
    "image_root = \"/media/arg_ws3/5E703E3A703E18EB/data/mm_FCN/unity/image/\"\n",
    "mask_root = \"/media/arg_ws3/5E703E3A703E18EB/data/mm_FCN/unity/mask/\"\n",
    "image_list = os.listdir(image_root)\n",
    "random.shuffle(image_list)\n",
    "print(len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9472\n"
     ]
    }
   ],
   "source": [
    "fcn_subt_root = '/media/arg_ws3/5E703E3A703E18EB/data/subt_all/'\n",
    "image_root = \"/media/arg_ws3/5E703E3A703E18EB/data/mm_FCN/unity/box_img/\"\n",
    "fcn_mask_root = \"/media/arg_ws3/5E703E3A703E18EB/data/mm_FCN/unity/box_mask/\"\n",
    "data_list = []\n",
    "training_box_list = []\n",
    "test_box_list = []\n",
    "count = 0\n",
    "for obj in os.listdir(image_root):\n",
    "    scene_path = os.path.join(image_root, obj)\n",
    "    fcn_scene_path = os.path.join(fcn_mask_root, obj)\n",
    "    scene_list = os.listdir(scene_path)\n",
    "    for scene in scene_list:\n",
    "        img_path = os.path.join(scene_path, scene)\n",
    "        fcn_img_path = os.path.join(fcn_scene_path, scene)\n",
    "        img_list = os.listdir(img_path)\n",
    "        for img in img_list:\n",
    "            file_path = os.path.join(img_path, img)\n",
    "            fcn_file_path = os.path.join(fcn_img_path, img.split('_original')[0] + '_label.png')\n",
    "            if os.path.exists(file_path) and os.path.exists(fcn_file_path):\n",
    "                data_list.append(obj+'/'+scene+'/'+img)\n",
    "            else:\n",
    "                print(obj+'/'+scene+'/'+img)\n",
    "random.shuffle(data_list)\n",
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78080\n"
     ]
    }
   ],
   "source": [
    "all_data_list = image_list + data_list\n",
    "random.shuffle(all_data_list)\n",
    "print(len(all_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70272\n",
      "7808\n"
     ]
    }
   ],
   "source": [
    "all_training_list = []\n",
    "all_testing_list = []\n",
    "ratio = 0.9\n",
    "count = 0\n",
    "for data in all_data_list:\n",
    "    if count < len(all_data_list)*ratio:\n",
    "        all_training_list.append(data)\n",
    "    else:\n",
    "        all_testing_list.append(data)\n",
    "    count = count + 1\n",
    "print(len(all_training_list))\n",
    "print(len(all_testing_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "with open(fcn_root + 'train_with_box_all.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    counter = 0\n",
    "    for image in all_training_list:\n",
    "        counter = counter +1\n",
    "        if image in image_list and image in data_list:\n",
    "            print(\"Wrong!!! \", image)\n",
    "        if image in image_list:\n",
    "            mask_name = image.split(\"_original.png\")[0] + \"_seg.png\"\n",
    "            writer.writerow([\"image/\" + image, \"mask/\" + mask_name])\n",
    "        elif image in data_list:\n",
    "            mask_name = image.split(\"_original.png\")[0] + \"_label.png\"\n",
    "            writer.writerow([\"box_img/\" + image, \"box_mask/\" + mask_name])\n",
    "        else:\n",
    "            print(\"Wrong!!! \", image)\n",
    "        if counter % 1000 == 0:\n",
    "            print(counter)\n",
    "with open(fcn_root + 'test_with_box_all.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    counter = 0\n",
    "    for image in all_testing_list:\n",
    "        counter = counter +1\n",
    "        if image in image_list and image in data_list:\n",
    "            print(\"Wrong!!! \", image)\n",
    "        if image in image_list:\n",
    "            mask_name = image.split(\"_original.png\")[0] + \"_seg.png\"\n",
    "            writer.writerow([\"image/\" + image, \"mask/\" + mask_name])\n",
    "        elif image in data_list:\n",
    "            mask_name = image.split(\"_original.png\")[0] + \"_label.png\"\n",
    "            writer.writerow([\"box_img/\" + image, \"box_mask/\" + mask_name])\n",
    "        else:\n",
    "            print(\"Wrong!!! \", image)\n",
    "        if counter % 1000 == 0:\n",
    "            print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
