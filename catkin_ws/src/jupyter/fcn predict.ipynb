{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.models.vgg import VGG\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import scipy.misc\n",
    "import random\n",
    "import sys\n",
    "\n",
    "if '/opt/ros/kinetic/lib/python2.7/dist-packages' in sys.path:\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "means     = np.array([103.939, 116.779, 123.68]) / 255. # mean of three channels in the order of BGR\n",
    "h, w      = 480, 640\n",
    "val_h     = h\n",
    "val_w     = w\n",
    "n_class = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN16s(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_net, n_class):\n",
    "        super().__init__()\n",
    "        self.n_class = n_class\n",
    "        self.pretrained_net = pretrained_net\n",
    "        self.relu    = nn.ReLU(inplace = True)\n",
    "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn1     = nn.BatchNorm2d(512)\n",
    "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn2     = nn.BatchNorm2d(256)\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn3     = nn.BatchNorm2d(128)\n",
    "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn4     = nn.BatchNorm2d(64)\n",
    "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn5     = nn.BatchNorm2d(32)\n",
    "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.pretrained_net(x)\n",
    "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
    "        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n",
    "\n",
    "        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
    "        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)\n",
    "        score = self.bn2(self.relu(self.deconv2(score)))  # size=(N, 256, x.H/8, x.W/8)\n",
    "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
    "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
    "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
    "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet(VGG):\n",
    "    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
    "        super().__init__(make_layers(cfg[model]))\n",
    "        self.ranges = ranges[model]\n",
    "\n",
    "        if pretrained:\n",
    "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
    "\n",
    "        if not requires_grad:\n",
    "            for param in super().parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n",
    "            del self.classifier\n",
    "\n",
    "        if show_params:\n",
    "            for name, param in self.named_parameters():\n",
    "                print(name, param.size())\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = {}\n",
    "\n",
    "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
    "        for idx in range(len(self.ranges)):\n",
    "            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):      \n",
    "                x = self.features[layer](x)\n",
    "            output[\"x%d\"%(idx+1)] = x\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = {\n",
    "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
    "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
    "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
    "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
    "}\n",
    "\n",
    "# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
    "cfg = {\n",
    "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if use_gpu:\\n    ts = time.time()\\n    vgg_model = vgg_model.cuda()\\n    fcn_model = fcn_model.cuda()\\n    fcn_model = nn.DataParallel(fcn_model, device_ids=num_gpu)\\n    print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "num_gpu = list(range(torch.cuda.device_count()))\n",
    "\n",
    "vgg_model = VGGNet(requires_grad=True, remove_fc=True)\n",
    "fcn_model = FCN16s(pretrained_net=vgg_model, n_class=n_class)\n",
    "use_gpu = False\n",
    "'''if use_gpu:\n",
    "    ts = time.time()\n",
    "    vgg_model = vgg_model.cuda()\n",
    "    fcn_model = fcn_model.cuda()\n",
    "    fcn_model = nn.DataParallel(fcn_model, device_ids=num_gpu)\n",
    "    print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class product_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, phase, n_class=n_class, flip_rate=0.):\n",
    "        self.data      = pd.read_csv(csv_file)\n",
    "        self.means     = means\n",
    "        self.n_class   = n_class\n",
    "        self.flip_rate = flip_rate\n",
    "        if phase == 'train':\n",
    "            self.flip_rate = 0.5\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name   = self.data.iloc[idx, 0]\n",
    "        img        = cv2.imread(os.path.join(data_dir, img_name),cv2.IMREAD_UNCHANGED)\n",
    "        label_name = self.data.iloc[idx, 1]\n",
    "        label      = cv2.imread(os.path.join(data_dir, label_name), cv2.IMREAD_GRAYSCALE)\n",
    "        origin_img = img\n",
    "        if random.random() < self.flip_rate:\n",
    "            img   = np.fliplr(img)\n",
    "            label = np.fliplr(label)\n",
    "\n",
    "        # reduce mean\n",
    "        img = img[:, :, ::-1]  # switch to BGR\n",
    "        \n",
    "        img = np.transpose(img, (2, 0, 1)) / 255.\n",
    "        img[0] -= self.means[0]\n",
    "        img[1] -= self.means[1]\n",
    "        img[2] -= self.means[2]\n",
    "\n",
    "        # convert to tensor\n",
    "        img = torch.from_numpy(img.copy()).float()\n",
    "        label = torch.from_numpy(label.copy()).long()\n",
    "\n",
    "        # create one-hot encoding\n",
    "        h, w = label.size()\n",
    "        target = torch.zeros(self.n_class, h, w)\n",
    "        \n",
    "        '''for i in range(n_class - 1):\n",
    "            if brand_class[i] in img_name:\n",
    "                target[i+1][label != 0] = 1\n",
    "                label[label != 0] = i+1\n",
    "                #print(brand_class[i], img_name,label_name)'''\n",
    "        for i in range(n_class):\n",
    "            target[i][label == i] = 1\n",
    "        \n",
    "        target[0][label == 0] = 1\n",
    "        #print(np.unique(label))\n",
    "        \n",
    " \n",
    "        sample = {'X': img, 'Y': target, 'l': label, 'origin': origin_img}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_use  = \"unity\" # \"unity\" \"histogram\" \"box_gan\"\n",
    "data_dir  = os.path.join(\"/media/arg_ws3/5E703E3A703E18EB/data/mm_FCN\", model_use)\n",
    "model_dir = os.path.join(\"/media/arg_ws3/5E703E3A703E18EB/research/mm_fcn/models\", model_use)\n",
    "if not os.path.exists(data_dir):\n",
    "    print(\"Data not found!\")\n",
    "val_file   = os.path.join(data_dir, \"predict.csv\")\n",
    "val_data   = product_dataset(csv_file = val_file, phase = 'val', flip_rate = 0)\n",
    "val_loader = DataLoader(val_data, batch_size = 4, num_workers = 0)\n",
    "\n",
    "dataiter = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model_name):\n",
    "    \n",
    "    # load pretrain models\n",
    "    state_dict = torch.load(os.path.join(model_dir, model_name))\n",
    "    fcn_model.load_state_dict(state_dict)\n",
    "    \n",
    "    batch = dataiter.next()\n",
    "    if use_gpu:\n",
    "        inputs = Variable(batch['X'].cuda())\n",
    "    else:\n",
    "        inputs = Variable(batch['X'])\n",
    "    img    = batch['origin'] \n",
    "    label  = batch['l']\n",
    "    \n",
    "    output = fcn_model(inputs)\n",
    "    output = output.data.cpu().numpy()\n",
    "\n",
    "    N, _, h, w = output.shape\n",
    "    pred = output.transpose(0, 2, 3, 1).reshape(-1, n_class).argmax(axis = 1).reshape(N, h, w)\n",
    "\n",
    "    # show images\n",
    "    plt.figure(figsize = (10, 12))\n",
    "    img = img.numpy()\n",
    "    for i in range(N):\n",
    "        img[i] = cv2.cvtColor(img[i], cv2.COLOR_BGR2RGB)\n",
    "        plt.subplot(N, 3, i*3 + 1)\n",
    "        plt.title(\"origin_img\")\n",
    "        plt.imshow(img[i])\n",
    "        #print(np.unique(_img[i]))\n",
    "\n",
    "        plt.subplot(N, 3, i*3 + 2)\n",
    "        plt.title(\"label_img\")\n",
    "        plt.imshow(label[i],cmap = \"brg\",vmin = 0, vmax = n_class - 1)\n",
    "\n",
    "        plt.subplot(N, 3, i*3 + 3)\n",
    "        plt.title(\"prediction\")\n",
    "        plt.imshow(pred[i],cmap = \"brg\",vmin = 0, vmax = n_class - 1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FCN16s:\n\tMissing key(s) in state_dict: \"pretrained_net.features.0.weight\", \"pretrained_net.features.0.bias\", \"pretrained_net.features.2.weight\", \"pretrained_net.features.2.bias\", \"pretrained_net.features.5.weight\", \"pretrained_net.features.5.bias\", \"pretrained_net.features.7.weight\", \"pretrained_net.features.7.bias\", \"pretrained_net.features.10.weight\", \"pretrained_net.features.10.bias\", \"pretrained_net.features.12.weight\", \"pretrained_net.features.12.bias\", \"pretrained_net.features.14.weight\", \"pretrained_net.features.14.bias\", \"pretrained_net.features.17.weight\", \"pretrained_net.features.17.bias\", \"pretrained_net.features.19.weight\", \"pretrained_net.features.19.bias\", \"pretrained_net.features.21.weight\", \"pretrained_net.features.21.bias\", \"pretrained_net.features.24.weight\", \"pretrained_net.features.24.bias\", \"pretrained_net.features.26.weight\", \"pretrained_net.features.26.bias\", \"pretrained_net.features.28.weight\", \"pretrained_net.features.28.bias\", \"deconv1.weight\", \"deconv1.bias\", \"bn1.weight\", \"bn1.running_var\", \"bn1.running_mean\", \"bn1.bias\", \"deconv2.weight\", \"deconv2.bias\", \"bn2.weight\", \"bn2.running_var\", \"bn2.running_mean\", \"bn2.bias\", \"deconv3.weight\", \"deconv3.bias\", \"bn3.weight\", \"bn3.running_var\", \"bn3.running_mean\", \"bn3.bias\", \"deconv4.weight\", \"deconv4.bias\", \"bn4.weight\", \"bn4.running_var\", \"bn4.running_mean\", \"bn4.bias\", \"deconv5.weight\", \"deconv5.bias\", \"bn5.weight\", \"bn5.running_var\", \"bn5.running_mean\", \"bn5.bias\", \"classifier.weight\", \"classifier.bias\". \n\tUnexpected key(s) in state_dict: \"module.pretrained_net.features.0.weight\", \"module.pretrained_net.features.0.bias\", \"module.pretrained_net.features.2.weight\", \"module.pretrained_net.features.2.bias\", \"module.pretrained_net.features.5.weight\", \"module.pretrained_net.features.5.bias\", \"module.pretrained_net.features.7.weight\", \"module.pretrained_net.features.7.bias\", \"module.pretrained_net.features.10.weight\", \"module.pretrained_net.features.10.bias\", \"module.pretrained_net.features.12.weight\", \"module.pretrained_net.features.12.bias\", \"module.pretrained_net.features.14.weight\", \"module.pretrained_net.features.14.bias\", \"module.pretrained_net.features.17.weight\", \"module.pretrained_net.features.17.bias\", \"module.pretrained_net.features.19.weight\", \"module.pretrained_net.features.19.bias\", \"module.pretrained_net.features.21.weight\", \"module.pretrained_net.features.21.bias\", \"module.pretrained_net.features.24.weight\", \"module.pretrained_net.features.24.bias\", \"module.pretrained_net.features.26.weight\", \"module.pretrained_net.features.26.bias\", \"module.pretrained_net.features.28.weight\", \"module.pretrained_net.features.28.bias\", \"module.deconv1.weight\", \"module.deconv1.bias\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.deconv2.weight\", \"module.deconv2.bias\", \"module.bn2.weight\", \"module.bn2.bias\", \"module.bn2.running_mean\", \"module.bn2.running_var\", \"module.bn2.num_batches_tracked\", \"module.deconv3.weight\", \"module.deconv3.bias\", \"module.bn3.weight\", \"module.bn3.bias\", \"module.bn3.running_mean\", \"module.bn3.running_var\", \"module.bn3.num_batches_tracked\", \"module.deconv4.weight\", \"module.deconv4.bias\", \"module.bn4.weight\", \"module.bn4.bias\", \"module.bn4.running_mean\", \"module.bn4.running_var\", \"module.bn4.num_batches_tracked\", \"module.deconv5.weight\", \"module.deconv5.bias\", \"module.bn5.weight\", \"module.bn5.bias\", \"module.bn5.running_mean\", \"module.bn5.running_var\", \"module.bn5.num_batches_tracked\", \"module.classifier.weight\", \"module.classifier.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0734a2822b1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FCNs_unity_batch10_epoch0_RMSprop_lr0.0001.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-a687ec1c929b>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# load pretrain models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfcn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 769\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FCN16s:\n\tMissing key(s) in state_dict: \"pretrained_net.features.0.weight\", \"pretrained_net.features.0.bias\", \"pretrained_net.features.2.weight\", \"pretrained_net.features.2.bias\", \"pretrained_net.features.5.weight\", \"pretrained_net.features.5.bias\", \"pretrained_net.features.7.weight\", \"pretrained_net.features.7.bias\", \"pretrained_net.features.10.weight\", \"pretrained_net.features.10.bias\", \"pretrained_net.features.12.weight\", \"pretrained_net.features.12.bias\", \"pretrained_net.features.14.weight\", \"pretrained_net.features.14.bias\", \"pretrained_net.features.17.weight\", \"pretrained_net.features.17.bias\", \"pretrained_net.features.19.weight\", \"pretrained_net.features.19.bias\", \"pretrained_net.features.21.weight\", \"pretrained_net.features.21.bias\", \"pretrained_net.features.24.weight\", \"pretrained_net.features.24.bias\", \"pretrained_net.features.26.weight\", \"pretrained_net.features.26.bias\", \"pretrained_net.features.28.weight\", \"pretrained_net.features.28.bias\", \"deconv1.weight\", \"deconv1.bias\", \"bn1.weight\", \"bn1.running_var\", \"bn1.running_mean\", \"bn1.bias\", \"deconv2.weight\", \"deconv2.bias\", \"bn2.weight\", \"bn2.running_var\", \"bn2.running_mean\", \"bn2.bias\", \"deconv3.weight\", \"deconv3.bias\", \"bn3.weight\", \"bn3.running_var\", \"bn3.running_mean\", \"bn3.bias\", \"deconv4.weight\", \"deconv4.bias\", \"bn4.weight\", \"bn4.running_var\", \"bn4.running_mean\", \"bn4.bias\", \"deconv5.weight\", \"deconv5.bias\", \"bn5.weight\", \"bn5.running_var\", \"bn5.running_mean\", \"bn5.bias\", \"classifier.weight\", \"classifier.bias\". \n\tUnexpected key(s) in state_dict: \"module.pretrained_net.features.0.weight\", \"module.pretrained_net.features.0.bias\", \"module.pretrained_net.features.2.weight\", \"module.pretrained_net.features.2.bias\", \"module.pretrained_net.features.5.weight\", \"module.pretrained_net.features.5.bias\", \"module.pretrained_net.features.7.weight\", \"module.pretrained_net.features.7.bias\", \"module.pretrained_net.features.10.weight\", \"module.pretrained_net.features.10.bias\", \"module.pretrained_net.features.12.weight\", \"module.pretrained_net.features.12.bias\", \"module.pretrained_net.features.14.weight\", \"module.pretrained_net.features.14.bias\", \"module.pretrained_net.features.17.weight\", \"module.pretrained_net.features.17.bias\", \"module.pretrained_net.features.19.weight\", \"module.pretrained_net.features.19.bias\", \"module.pretrained_net.features.21.weight\", \"module.pretrained_net.features.21.bias\", \"module.pretrained_net.features.24.weight\", \"module.pretrained_net.features.24.bias\", \"module.pretrained_net.features.26.weight\", \"module.pretrained_net.features.26.bias\", \"module.pretrained_net.features.28.weight\", \"module.pretrained_net.features.28.bias\", \"module.deconv1.weight\", \"module.deconv1.bias\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.deconv2.weight\", \"module.deconv2.bias\", \"module.bn2.weight\", \"module.bn2.bias\", \"module.bn2.running_mean\", \"module.bn2.running_var\", \"module.bn2.num_batches_tracked\", \"module.deconv3.weight\", \"module.deconv3.bias\", \"module.bn3.weight\", \"module.bn3.bias\", \"module.bn3.running_mean\", \"module.bn3.running_var\", \"module.bn3.num_batches_tracked\", \"module.deconv4.weight\", \"module.deconv4.bias\", \"module.bn4.weight\", \"module.bn4.bias\", \"module.bn4.running_mean\", \"module.bn4.running_var\", \"module.bn4.num_batches_tracked\", \"module.deconv5.weight\", \"module.deconv5.bias\", \"module.bn5.weight\", \"module.bn5.bias\", \"module.bn5.running_mean\", \"module.bn5.running_var\", \"module.bn5.num_batches_tracked\", \"module.classifier.weight\", \"module.classifier.bias\". "
     ]
    }
   ],
   "source": [
    "prediction(\"FCNs_unity_batch10_epoch0_RMSprop_lr0.0001.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
