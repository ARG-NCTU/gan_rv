{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [  nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features)  ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorResNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, res_blocks=9):\n",
    "        super(GeneratorResNet, self).__init__()\n",
    "\n",
    "        # Initial convolution block\n",
    "        model = [   nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(in_channels, 64, 7),\n",
    "                    nn.InstanceNorm2d(64),\n",
    "                    nn.ReLU(inplace=True) ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(res_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features//2\n",
    "\n",
    "        # Output layer\n",
    "        model += [  nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(64, out_channels, 7),\n",
    "                    nn.Tanh() ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        self.n1 = nn.Sequential(*discriminator_block(in_channels, 64, normalize=False))\n",
    "        self.n2 = nn.Sequential(*discriminator_block(64, 128))\n",
    "        self.n3 = nn.Sequential(*discriminator_block(128, 256))\n",
    "        self.n4 = nn.Sequential(*discriminator_block(256, 512))\n",
    "        self.n5 = nn.ZeroPad2d((1,0,1,0))\n",
    "        self.n6 = nn.Conv2d(512, 1, 4, padding=1)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels, 64, normalize=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        print(img.shape)\n",
    "        x = self.n1(img)\n",
    "        print(x.shape)\n",
    "        x = self.n2(x)\n",
    "        print(x.shape)\n",
    "        x = self.n3(x)\n",
    "        print(x.shape)\n",
    "        x = self.n4(x)\n",
    "        print(x.shape)\n",
    "        x = self.n5(x)\n",
    "        print(x.shape)\n",
    "        x = self.n6(x)\n",
    "        print(x.shape)\n",
    "        #return self.model(img)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 480, 640])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"/home/arg_ws3/Pictures/Wallpapers/NickWang.jpg\")\n",
    "img_height = 480\n",
    "img_width = 640\n",
    "tfs = [ transforms.Resize((img_height, img_width), Image.BICUBIC),\n",
    "                #transforms.RandomCrop((img_height, img_width)),\n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "transforms_ = transforms.Compose(tfs)\n",
    "item = transforms_(img)\n",
    "item = Variable(item)\n",
    "\n",
    "item = item.unsqueeze(0)\n",
    "item.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (n1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (n2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (n3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (n4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (n5): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
       "  (n6): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (11): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
       "    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 480, 640])\n",
      "torch.Size([1, 64, 240, 320])\n",
      "torch.Size([1, 128, 120, 160])\n",
      "torch.Size([1, 256, 60, 80])\n",
      "torch.Size([1, 512, 30, 40])\n",
      "torch.Size([1, 512, 31, 41])\n",
      "torch.Size([1, 1, 30, 40])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 30, 40])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = d(item)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = d(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 15, 20])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(testNet, self).__init__()\n",
    "        self.base_model = torchvision.models.alexnet(pretrained = True)\n",
    "        print(self.base_model)\n",
    "        self.base_features = self.base_model.features\n",
    "        for param in self.base_features.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Everything except the last linear layer\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, (4, 4), (2, 2), (1,1)), #in, out, kernel, stride, padding\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)), #in, out, kernel, stride, padding\n",
    "            nn.InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)), #in, out, kernel, stride, padding\n",
    "            nn.InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1)), #in, out, kernel, stride, padding\n",
    "            nn.InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0))\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
    "        )\n",
    "        self.new_classifier = nn.Sequential(\n",
    "            nn.Linear(4099, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        print(\"conv1: \", x1.shape)\n",
    "        x2 = self.conv2(x1)\n",
    "        print(\"conv2: \", x2.shape)\n",
    "        x3 = self.conv3(x2)\n",
    "        print(\"conv3: \", x3.shape)\n",
    "        x4 = self.conv4(x3)\n",
    "        print(\"conv4: \", x4.shape)\n",
    "        x5 = self.conv5(x4)\n",
    "        print(\"conv5: \", x5.shape)\n",
    "        f_out = self.base_features(x)\n",
    "        #f_out = f_out.view(1, -1)\n",
    "        print(\"features: \", f_out.shape)\n",
    "        output = x5\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "test = testNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1:  torch.Size([1, 64, 120, 160])\n",
      "conv2:  torch.Size([1, 128, 60, 80])\n",
      "conv3:  torch.Size([1, 256, 30, 40])\n",
      "conv4:  torch.Size([1, 512, 16, 21])\n",
      "conv5:  torch.Size([1, 1, 15, 20])\n",
      "features:  torch.Size([1, 256, 6, 9])\n"
     ]
    }
   ],
   "source": [
    "t = test(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 15, 20])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.6396e-01,  1.3731e-01,  4.5993e-01,  2.6904e-01,  2.0481e-01,\n",
       "            4.3343e-01, -2.4109e-02,  3.4406e-01, -9.8886e-02,  3.9919e-01,\n",
       "            7.9689e-02,  2.9744e-01, -2.9480e-01, -4.1103e-01,  4.2609e-01,\n",
       "            8.0310e-01,  7.1511e-01,  4.7087e-01,  2.0060e-01, -1.7292e-02],\n",
       "          [ 2.2782e-01,  3.4933e-01,  5.1855e-01, -6.6352e-02,  2.6952e-02,\n",
       "           -1.3521e-01, -6.2806e-01,  3.8714e-01,  1.9291e-02,  3.7754e-01,\n",
       "            5.6412e-01, -3.0544e-02,  2.8047e-01,  4.7832e-01, -3.2351e-01,\n",
       "            3.2049e-01,  5.5928e-01,  4.8534e-01, -2.1460e-02, -2.3494e-01],\n",
       "          [ 2.2897e-01,  2.7126e-01,  2.1209e-01,  4.2137e-01, -2.4208e-01,\n",
       "           -2.8636e-01, -5.5804e-02, -1.5814e-01, -3.5224e-01,  2.0652e-01,\n",
       "            1.8558e-01,  3.2440e-01,  5.1743e-03,  1.5944e-01, -2.0050e-01,\n",
       "           -9.7395e-02,  4.1364e-01,  3.8662e-01,  2.2204e-01, -2.6767e-01],\n",
       "          [ 2.7021e-01,  9.5274e-02,  4.0826e-01, -2.5264e-01, -2.7920e-01,\n",
       "            3.2827e-01,  1.4525e-01,  5.6842e-01,  8.6218e-01,  9.6951e-01,\n",
       "            1.0885e+00,  6.6314e-01,  3.7422e-01,  4.5513e-01,  5.1813e-01,\n",
       "            5.8049e-01, -5.3072e-01,  3.0333e-01,  1.2842e-01, -3.9524e-01],\n",
       "          [ 2.1473e-01,  5.9070e-03, -2.0025e-01,  1.5388e-01,  4.9430e-01,\n",
       "           -1.7372e-01,  4.6286e-01, -1.3835e-01,  5.3674e-01,  5.6022e-01,\n",
       "            8.7585e-02, -1.5769e-01,  2.5770e-01,  3.8011e-01,  3.7507e-01,\n",
       "           -5.7849e-02,  1.0860e-02, -3.4060e-02, -3.5902e-01, -4.1548e-01],\n",
       "          [ 1.6236e-01, -3.9438e-01, -1.2952e-01,  2.9413e-01,  4.8944e-02,\n",
       "           -4.0674e-01, -4.9510e-01, -4.7874e-01, -4.2020e-01, -3.3380e-01,\n",
       "           -3.1489e-01, -1.5914e-01,  2.2431e-01,  7.8098e-01,  8.5986e-01,\n",
       "            3.2503e-01,  2.5419e-01,  7.7106e-02,  5.9030e-02, -4.0571e-01],\n",
       "          [ 1.1617e-01, -1.3261e-01,  1.8604e-01,  2.5790e-01,  4.0383e-01,\n",
       "           -1.2927e-01, -4.4208e-01, -1.3989e-01, -1.9754e-01,  4.4348e-01,\n",
       "            1.5285e-02,  6.0712e-02, -1.3850e-01, -9.1640e-02,  4.4189e-01,\n",
       "            1.9628e-01,  4.2925e-01,  1.9781e-01, -5.3678e-02, -4.1111e-01],\n",
       "          [ 6.1019e-02, -1.9930e-01,  1.7756e-01, -1.5042e-01,  2.8595e-01,\n",
       "           -9.3065e-02, -3.2359e-01, -2.5169e-01, -4.9669e-01, -7.2097e-01,\n",
       "           -3.9807e-01, -2.6159e-01, -6.4319e-01, -1.0162e-01,  2.0441e-01,\n",
       "           -7.9624e-02,  6.0955e-02, -3.1828e-02, -1.2462e-01, -3.9298e-01],\n",
       "          [ 5.6917e-02, -1.8573e-01, -1.4522e-01, -1.1388e-01,  2.0675e-01,\n",
       "           -1.9508e-01, -2.0675e-01,  4.0586e-01, -9.6790e-02,  2.1192e-01,\n",
       "            1.0336e-01,  2.2825e-01, -1.4093e-01, -4.9364e-02, -3.8514e-01,\n",
       "           -3.3174e-02,  2.1833e-02,  1.2965e-01, -1.8211e-01, -2.5222e-01],\n",
       "          [ 8.9889e-02, -2.3016e-01,  1.9680e-02, -2.7275e-03, -3.3396e-01,\n",
       "           -1.5825e-01,  5.9991e-02,  3.3774e-01, -2.4254e-01,  1.0244e-02,\n",
       "           -6.7335e-01, -4.3780e-01, -1.8515e-01, -4.8965e-01, -1.3103e-01,\n",
       "           -2.2981e-01, -2.2408e-01,  1.6217e-01, -1.3946e-01, -4.9550e-01],\n",
       "          [ 1.4937e-01, -6.8208e-02, -5.7214e-03, -1.0925e-01, -3.3823e-01,\n",
       "            3.2536e-05, -2.5629e-01,  8.1312e-02, -1.3564e-01, -2.6687e-01,\n",
       "           -8.1267e-01, -9.2955e-01, -4.0666e-02, -8.0204e-04, -1.8438e-01,\n",
       "            9.1905e-02, -1.4272e-01,  9.1439e-02, -7.1152e-03, -3.8722e-01],\n",
       "          [ 9.3779e-02, -1.0417e-01, -1.7344e-01, -2.2673e-01,  3.1723e-02,\n",
       "            2.9016e-02,  1.7067e-01,  2.2250e-01, -1.8445e-01,  1.6713e-01,\n",
       "           -9.2600e-01, -5.2541e-01, -1.9067e-01,  1.9351e-02, -8.1527e-02,\n",
       "            9.7600e-02, -5.5375e-02,  1.1593e-01, -1.7541e-01, -1.3437e-01],\n",
       "          [ 1.0238e-01,  2.7747e-02,  2.0376e-01,  4.8757e-02,  3.2686e-01,\n",
       "           -1.1945e-01,  1.7347e-01, -2.6708e-02, -4.1109e-01, -2.9134e-01,\n",
       "           -1.1961e-01, -1.1796e-01, -2.0290e-01, -1.5660e-02, -2.2924e-01,\n",
       "           -1.1695e-02,  1.8073e-01, -5.7759e-02, -2.5512e-01, -5.7616e-02],\n",
       "          [ 5.7536e-02,  2.6005e-01, -2.1686e-01, -1.4913e-01,  1.2108e-01,\n",
       "            1.3038e-01,  3.3487e-01,  8.2512e-02,  2.8869e-01,  1.4593e-01,\n",
       "           -1.1878e-01,  3.0469e-01,  4.4174e-01,  1.9160e-01, -3.0436e-01,\n",
       "           -1.4133e-01,  2.7974e-01, -3.7463e-02,  1.3585e-01,  6.9559e-02],\n",
       "          [ 4.1078e-02,  1.9143e-02,  1.2749e-01,  2.5186e-01,  2.8171e-01,\n",
       "            1.9715e-01,  3.8640e-01, -9.1743e-02,  4.3813e-01, -8.6070e-04,\n",
       "           -8.8702e-02,  4.5454e-01,  4.7858e-01, -2.0825e-01, -1.8321e-02,\n",
       "           -2.3707e-01,  8.9789e-02,  8.0232e-03, -2.0711e-01, -3.6739e-02]]]],\n",
       "       grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
