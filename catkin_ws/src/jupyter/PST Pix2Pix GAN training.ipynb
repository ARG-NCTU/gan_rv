{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.models.vgg import VGG\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import scipy.misc\n",
    "import random\n",
    "import sys\n",
    "\n",
    "if '/opt/ros/kinetic/lib/python2.7/dist-packages' in sys.path:\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        # Concatenate image and condition image by channels to produce input\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define U-Net model for deconvolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDown(nn.Module):\n",
    "    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n",
    "        super(UNetDown, self).__init__()\n",
    "        layers = [nn.Conv2d(in_size, out_size, 4, 2, 1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_size))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class UNetUp(nn.Module):\n",
    "    def __init__(self, in_size, out_size, dropout=0.0):\n",
    "        super(UNetUp, self).__init__()\n",
    "        layers = [  nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),\n",
    "                    nn.InstanceNorm2d(out_size),\n",
    "                    nn.ReLU(inplace=True)]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip_input):\n",
    "        x = self.model(x)\n",
    "        x = torch.cat((x, skip_input), 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "class GeneratorUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=5):\n",
    "        super(GeneratorUNet, self).__init__()\n",
    "\n",
    "        self.down1 = UNetDown(in_channels, 64, normalize=False)\n",
    "        self.down2 = UNetDown(64, 128)\n",
    "        self.down3 = UNetDown(128, 256)\n",
    "        self.down4 = UNetDown(256, 512, dropout=0.5)\n",
    "        self.down5 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down6 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down7 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)\n",
    "\n",
    "        self.up1 = UNetUp(512, 512, dropout=0.5)\n",
    "        self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up3 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up4 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up5 = UNetUp(1024, 256)\n",
    "        self.up6 = UNetUp(512, 128)\n",
    "        self.up7 = UNetUp(256, 64)\n",
    "\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, out_channels, 4, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # U-Net generator with skip connections from encoder to decoder\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "        u1 = self.up1(d8, d7)\n",
    "        u2 = self.up2(u1, d6)\n",
    "        u3 = self.up3(u2, d5)\n",
    "        u4 = self.up4(u3, d4)\n",
    "        u5 = self.up5(u4, d3)\n",
    "        u6 = self.up6(u5, d2)\n",
    "        u7 = self.up7(u6, d1)\n",
    "\n",
    "        return self.final(u7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define VGG16 for convolution layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs     = 200  #500\n",
    "lr         = 1e-4\n",
    "momentum   = 0\n",
    "w_decay    = 1e-5\n",
    "step_size  = 50\n",
    "gamma      = 0.5\n",
    "n_class = 5\n",
    "model_use = \"pst_unet_gan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define path, directory trainning environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish cuda loading, time elapsed 4.76837158203125e-07\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "data_dir  = os.path.join(\"/media/arg_ws3/5E703E3A703E18EB/data/PST900_RGBT_Dataset/\")\n",
    "if not os.path.exists(data_dir):\n",
    "    print(\"Data not found!\")\n",
    "# create dir for model\n",
    "model_dir = os.path.join(\"/media/arg_ws3/5E703E3A703E18EB/research/subt_fcn/models\", model_use)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "# create dir for score\n",
    "score_dir = os.path.join(\"/media/arg_ws3/5E703E3A703E18EB/research/subt_fcn/scores\", model_use)\n",
    "if not os.path.exists(score_dir):\n",
    "    os.makedirs(score_dir)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "num_gpu = list(range(torch.cuda.device_count()))\n",
    "\n",
    "generator = GeneratorUNet(in_channels=3, out_channels=n_class)\n",
    "\n",
    "if use_gpu:\n",
    "    ts = time.time()\n",
    "    print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means     = np.array([103.939, 116.779, 123.68]) / 255. # mean of three channels in the order of BGR\n",
    "h, w      = 256, 256\n",
    "val_h     = h\n",
    "val_w     = w\n",
    "\n",
    "class product_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, root, phase, n_class=n_class, flip_rate=0.):\n",
    "        data_dir = os.path.join(root, phase)\n",
    "        self.img_list = os.listdir(os.path.join(data_dir, 'rgb'))\n",
    "        self.rgb_dir = os.path.join(data_dir, 'rgb')\n",
    "        self.label_dir = os.path.join(data_dir, 'labels')\n",
    "        self.means     = means\n",
    "        self.n_class   = n_class\n",
    "        self.flip_rate = flip_rate\n",
    "        if phase == 'train':\n",
    "            self.flip_rate = 0.5\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx % len(self.img_list)\n",
    "        img = cv2.imread(os.path.join(self.rgb_dir, self.img_list[idx]),cv2.IMREAD_UNCHANGED)\n",
    "        label = cv2.imread(os.path.join(self.label_dir, self.img_list[idx]), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        label = cv2.resize(label, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        origin_img = img\n",
    "        if random.random() < self.flip_rate:\n",
    "            img   = np.fliplr(img)\n",
    "            label = np.fliplr(label)\n",
    "\n",
    "        # reduce mean\n",
    "        img = img[:, :, ::-1]  # switch to BGR\n",
    "        \n",
    "        img = np.transpose(img, (2, 0, 1)) / 255.\n",
    "        img[0] -= self.means[0]\n",
    "        img[1] -= self.means[1]\n",
    "        img[2] -= self.means[2]\n",
    "\n",
    "        # convert to tensor\n",
    "        img = torch.from_numpy(img.copy()).float()\n",
    "        label = torch.from_numpy(label.copy()).long()\n",
    "\n",
    "        # create one-hot encoding\n",
    "        h, w = label.size()\n",
    "        target = torch.zeros(self.n_class, h, w)\n",
    "        \n",
    "        for i in range(n_class):\n",
    "            target[i][label == i] = 1\n",
    "        \n",
    "        #target[0][label == 0] = 1\n",
    "        #print(np.unique(label))\n",
    "        \n",
    " \n",
    "        sample = {'X': img, 'Y': target, 'l': label, 'origin': origin_img}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataloader and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial dataloader for trainning and validation\n",
    "train_data = product_dataset(data_dir, phase = 'train')\n",
    "val_data   = product_dataset(data_dir, phase = 'test', flip_rate = 0)\n",
    "dataloader = DataLoader(train_data, batch_size = batch_size, shuffle=True, num_workers = 0)\n",
    "val_loader = DataLoader(val_data, batch_size = 1, num_workers = 0)\n",
    "\n",
    "dataiter = iter(val_loader)\n",
    "\n",
    "# define loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#optimizer = optim.RMSprop(generator.parameters(), lr = lr, momentum = momentum, weight_decay = w_decay)\n",
    "# decay LR by a factor of 0.5 every step_size = 50 epochs\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size = step_size, gamma = gamma)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(in_channels = n_class + 3)\n",
    "# Loss functions\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_pixelwise = torch.nn.L1Loss()\n",
    "patch = (1, 256//2**4, 256//2**4)\n",
    "# Loss weight of L1 pixel-wise loss between translated image and real image\n",
    "lambda_pixel = 100\n",
    "\n",
    "if use_gpu:\n",
    "    discriminator = discriminator.cuda()\n",
    "    generator = generator.cuda()\n",
    "    criterion_GAN.cuda()\n",
    "    criterion_pixelwise.cuda()\n",
    "Tensor = torch.cuda.FloatTensor if use_gpu else torch.FloatTensor\n",
    "discriminator.apply(weights_init_normal)\n",
    "generator.apply(weights_init_normal)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "scheduler_d = lr_scheduler.StepLR(optimizer_D, step_size = step_size+10, gamma = gamma)\n",
    "scheduler_g = lr_scheduler.StepLR(optimizer_G, step_size = step_size+10, gamma = gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    generator.eval()\n",
    "    TP = np.zeros(n_class-1, dtype = np.float128)\n",
    "    FN = np.zeros(n_class-1, dtype = np.float128)\n",
    "    FP = np.zeros(n_class-1, dtype = np.float128)\n",
    "    total_ious = []\n",
    "    pixel_accs = []\n",
    "    for iter, batch in enumerate(val_loader):\n",
    "        if use_gpu:\n",
    "            inputs = Variable(batch['X'].cuda())\n",
    "        else:\n",
    "            inputs = Variable(batch['X'])\n",
    "\n",
    "        output = generator(inputs)\n",
    "        output = output.data.cpu().numpy()\n",
    "\n",
    "        N, _, h, w = output.shape\n",
    "        pred = output.transpose(0, 2, 3, 1).reshape(-1, n_class).argmax(axis=1).reshape(N, h, w)\n",
    "\n",
    "        print(batch['l'].shape)\n",
    "        target = batch['l'].cpu().numpy().reshape(N, h, w)\n",
    "        for p, t in zip(pred, target):\n",
    "            pixel_accs.append(pixel_acc(p, t))\n",
    "            _TP, _FN, _FP =  analysis(p, t, h, w)\n",
    "            TP += _TP[1:n_class]\n",
    "            FN += _FN[1:n_class]\n",
    "            FP += _FP[1:n_class]\n",
    "            \n",
    "    recall = TP / (TP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    ious = TP / (TP + FN + FP)\n",
    "    fscore = 2*TP / (2*TP + FN + FP)\n",
    "    total_ious = np.array(total_ious).T  # n_class * val_len\n",
    "    pixel_accs = np.array(pixel_accs).mean()\n",
    "    \n",
    "    #print(\"epoch{}, pix_acc: {}, meanIoU: {}, IoUs: {}, recall: {}, precision: {}, fscore: {}\"\\\n",
    "    #      .format(epoch, pixel_accs, np.nanmean(ious), ious, recall, precision, fscore))\n",
    "    print(\"epoch{}, meanIoU: {}\".format(epoch, np.nanmean(ious)))\n",
    "    \n",
    "    f1 = open(score_dir + \"/cls_acc_log.txt\",\"a+\")\n",
    "    f1.write('epoch:'+ str(epoch) + ', pix_acc: ' + str(pixel_accs) + '\\n' )\n",
    "    f2 = open(score_dir + \"/cls_iou_log.txt\",\"a+\")\n",
    "    f2.write('epoch:'+ str(epoch) + ', class ious: ' + str(ious) + '\\n' )\n",
    "    f3 = open(score_dir + \"/mean_iou_log.txt\",\"a+\")\n",
    "    f3.write('epoch:'+ str(epoch) + ', mean IoU: ' + str(np.nanmean(ious)) + '\\n' ) \n",
    "    f4 = open(score_dir + \"/recall_log.txt\",\"a+\")\n",
    "    f4.write('epoch:'+ str(epoch) + ', class recall: ' + str(recall) + '\\n' )\n",
    "    f5 = open(score_dir + \"/precision_log.txt\",\"a+\")\n",
    "    f5.write('epoch:'+ str(epoch) + ', class precision: ' + str(precision) + '\\n' )    \n",
    "    f6 = open(score_dir + \"/fscore_log.txt\",\"a+\")\n",
    "    f6.write('epoch:'+ str(epoch) + ', class fscore: ' + str(fscore) + '\\n' )  \n",
    "    f7 = open(score_dir + \"/mean_fscore_log.txt\",\"a+\")\n",
    "    f7.write('epoch:'+ str(epoch) + ', mean fscore: ' + str(np.nanmean(fscore)) + '\\n' )\n",
    "    f8 = open(score_dir + \"/mean_precision_log.txt\",\"a+\")\n",
    "    f8.write('epoch:'+ str(epoch) + ', mean precision: ' + str(np.nanmean(precision)) + '\\n' ) \n",
    "    f9 = open(score_dir + \"/mean_recall_log.txt\",\"a+\")\n",
    "    f9.write('epoch:'+ str(epoch) + ', mean recall: ' + str(np.nanmean(recall)) + '\\n' ) \n",
    "    \n",
    "\n",
    "def analysis(pred, target, h, w):\n",
    "    # TP, FN, FP, TN\n",
    "    TP = np.zeros(n_class, dtype = np.float128)\n",
    "    FN = np.zeros(n_class, dtype = np.float128)\n",
    "    FP = np.zeros(n_class, dtype = np.float128)\n",
    "\n",
    "    target = target.reshape(h * w)\n",
    "    pred = pred.reshape(h * w)\n",
    "\n",
    "    con_matrix = confusion_matrix(target, pred,labels = np.arange(0,n_class,1))\n",
    "    con_matrix[0][0] = 0\n",
    "    for i in range(0, n_class):\n",
    "        for j in range(0, n_class):\n",
    "            if i == j:\n",
    "                TP[i] += con_matrix[i][j]\n",
    "            if i != j:\n",
    "                FP[j] += con_matrix[i][j]\n",
    "                FN[i] += con_matrix[i][j]\n",
    "    return TP, FN, FP\n",
    "                \n",
    "def pixel_acc(pred, target):\n",
    "    correct = (pred == target).sum()\n",
    "    total   = (target == target).sum()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(epochs):\n",
    "        generator.train()\n",
    "        #scheduler.step()\n",
    "        scheduler_d.step()\n",
    "        scheduler_g.step()\n",
    "        configs    = \"FCNs_batch{}_epoch{}_RMSprop_lr{}\"\\\n",
    "            .format(batch_size, epoch, lr)\n",
    "        model_path = os.path.join(model_dir, configs)\n",
    "        \n",
    "        ts = time.time()\n",
    "        for iter, batch in enumerate(dataloader):\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs = Variable(batch['X'].cuda())\n",
    "                labels = Variable(batch['Y'].cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(batch['X']), Variable(batch['Y'])\n",
    "\n",
    "            valid = Variable(Tensor(np.ones((labels.size(0), *patch))), requires_grad=False)\n",
    "            fake = Variable(Tensor(np.zeros((labels.size(0), *patch))), requires_grad=False)\n",
    "                \n",
    "            outputs = generator(inputs)\n",
    "            # GAN loss\n",
    "            pred_fake = discriminator(outputs, inputs)\n",
    "            loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "            # ADV loss\n",
    "            #pred_adv = discriminator_adv(outputs, temp)\n",
    "            #loss_adv = criterion_adv(pred_adv, valid)\n",
    "            # Pixel-wise loss\n",
    "            loss_pixel = criterion(outputs, labels)\n",
    "            #loss_G = 0.005 * loss_GAN + loss_pixel + 0.005 * loss_adv\n",
    "            #loss_G = loss_pixel + 0.01 * loss_adv\n",
    "            loss_G = 0.005 * loss_GAN + loss_pixel\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = discriminator(labels, inputs)\n",
    "            loss_real = criterion_GAN(pred_real, valid)\n",
    "            #pred_adv_real = discriminator_adv(outputs.detach(),labels)\n",
    "            #loss_adv_real = criterion_adv(pred_adv_real, valid)\n",
    "\n",
    "            # Fake loss\n",
    "            pred_fake = discriminator(outputs.detach(), inputs)\n",
    "            loss_fake = criterion_GAN(pred_fake, fake)\n",
    "            #pred_adv_fake = discriminator_adv(outputs.detach(), temp)\n",
    "            #loss_adv_fake = criterion_adv(pred_adv_fake, fake)\n",
    "\n",
    "            # Total loss\n",
    "            #loss_D = 0.25*0.5 * (loss_real + loss_fake) + 0.25*0.5 * (loss_adv_real + loss_adv_fake)\n",
    "            #loss_D = 0.5 * (loss_adv_real + loss_adv_fake)\n",
    "            loss_D = 0.5 * (loss_real + loss_fake)\n",
    "\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            \n",
    "            if iter % 10 == 0:\n",
    "                #print(\"epoch{}, iter{}, loss_G: {}, loss_D: {}\".format(epoch+1, iter, loss_G.item(), loss_D.item()))\n",
    "                print(\"epoch{}, iter{}, loss_G: {}\".format(epoch+1, iter, loss_G.item()))\n",
    "        \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        if epoch % 4 == 0:\n",
    "            torch.save(generator.state_dict(),model_path + '.pkl')\n",
    "\n",
    "        val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arg_ws3/.local/lib/python3.5/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1, iter0, loss_G: 0.7297750115394592\n",
      "epoch1, iter10, loss_G: 0.4814739227294922\n",
      "epoch1, iter20, loss_G: 0.3810272514820099\n",
      "epoch1, iter30, loss_G: 0.35287824273109436\n",
      "epoch1, iter40, loss_G: 0.34179046750068665\n",
      "epoch1, iter50, loss_G: 0.3458089530467987\n",
      "epoch1, iter60, loss_G: 0.34117481112480164\n",
      "epoch1, iter70, loss_G: 0.3291923403739929\n",
      "Finish epoch 0, time elapsed 31.498277187347412\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arg_ws3/.local/lib/python3.5/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/arg_ws3/.local/lib/python3.5/site-packages/ipykernel_launcher.py:55: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, meanIoU: 0.0\n",
      "epoch2, iter0, loss_G: 0.33559152483940125\n",
      "epoch2, iter10, loss_G: 0.3334239721298218\n",
      "epoch2, iter20, loss_G: 0.336772620677948\n",
      "epoch2, iter30, loss_G: 0.3343350887298584\n",
      "epoch2, iter40, loss_G: 0.3284060060977936\n",
      "epoch2, iter50, loss_G: 0.33637118339538574\n",
      "epoch2, iter60, loss_G: 0.3296355903148651\n",
      "epoch2, iter70, loss_G: 0.34390246868133545\n",
      "Finish epoch 1, time elapsed 31.39460849761963\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "epoch1, meanIoU: 0.0\n",
      "epoch3, iter0, loss_G: 0.32286491990089417\n",
      "epoch3, iter10, loss_G: 0.3343763053417206\n",
      "epoch3, iter20, loss_G: 0.3308301568031311\n",
      "epoch3, iter30, loss_G: 0.32969963550567627\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data   = product_dataset(data_dir, phase = 'test', flip_rate = 0)\n",
    "val_loader = DataLoader(val_data, batch_size = 1, num_workers = 0)\n",
    "dataiter = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model_name):\n",
    "    \n",
    "    # load pretrain models\n",
    "    state_dict = torch.load(os.path.join(model_name))\n",
    "    generator.load_state_dict(state_dict)\n",
    "    \n",
    "    batch = dataiter.next()\n",
    "    if use_gpu:\n",
    "        inputs = Variable(batch['X'].cuda())\n",
    "    else:\n",
    "        inputs = Variable(batch['X'])\n",
    "    img    = batch['origin'] \n",
    "    label  = batch['l']\n",
    "    \n",
    "    #print(img.shape, inputs.shape)\n",
    "    #print(inputs[0])\n",
    "    \n",
    "    output = generator(inputs)\n",
    "    output = output.data.cpu().numpy()\n",
    "\n",
    "    N, _, h, w = output.shape\n",
    "    pred = output.transpose(0, 2, 3, 1).reshape(-1, n_class).argmax(axis = 1).reshape(N, h, w)\n",
    "\n",
    "    # show images\n",
    "    plt.figure(figsize = (10, 12))\n",
    "    img = img.numpy()\n",
    "    for i in range(N):\n",
    "        img[i] = cv2.cvtColor(img[i], cv2.COLOR_BGR2RGB)\n",
    "        plt.subplot(N, 3, i*3 + 1)\n",
    "        plt.title(\"origin_img\")\n",
    "        plt.imshow(img[i])\n",
    "        #print(np.unique(_img[i]))\n",
    "\n",
    "        plt.subplot(N, 3, i*3 + 2)\n",
    "        plt.title(\"label_img\")\n",
    "        plt.imshow(label[i],cmap = \"nipy_spectral\",vmin = 0, vmax = n_class - 1)\n",
    "\n",
    "        plt.subplot(N, 3, i*3 + 3)\n",
    "        plt.title(\"prediction\")\n",
    "        plt.imshow(pred[i],cmap = \"nipy_spectral\",vmin = 0, vmax = n_class - 1)\n",
    "    y = pred[0].astype(np.uint8)\n",
    "    #y = cv2.cvtColor(y, cv2.COLOR_GRAY2RGB)\n",
    "    plt.imsave(\"/media/arg_ws3/5E703E3A703E18EB/research/subt_fcn/models/pst/b_6.jpg\", y, cmap='nipy_spectral',vmin = 0, vmax = n_class - 1)\n",
    "    #cv2.imwrite(\"/media/arg_ws3/5E703E3A703E18EB/research/subt_fcn/models/pst/a.jpg\", y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(\"/media/arg_ws3/5E703E3A703E18EB/research/subt_fcn/models/pst_gan/FCNs_batch8_epoch140_RMSprop_lr0.0001.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
